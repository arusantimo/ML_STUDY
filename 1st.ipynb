{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>1,2회차 실습 예제</b>\n",
    "\n",
    "* 총 6단계로 1,2회차 실습으로 나눠서 진행\n",
    "    1. 파이썬 실치 해보기 (skip 가능) or colab등으로 실습 환경 마련가능\n",
    "    2. 데이터셋을 만들어야합니다.\n",
    "    3. 데이터셋 시각화\n",
    "    4. 다음 실습때... 학습 제대로\n",
    "    5. \n",
    "    6. \n",
    "* 만들어 볼 것은 이미지 분류기(classifier)입니다.\n",
    "    * 데이터 수집/정제\n",
    "    * 인공지능 모델 학습\n",
    "    * 학습된 모델 배포"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1회차 실습 코드\n",
    "\n",
    "환경 구성 3가지 케이스\n",
    "\n",
    "\n",
    "1.코랩을 사용하면 설치하지 않아도 됩니다.  \n",
    "2. vscode 설치시 필요한 플러그인 자동 설치 됩니다.\n",
    "\n",
    "[설치 설명](https://arusantimo.notion.site/b0992d1aee0d42ae9f2cbd8ac730a481)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설치 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트 설치하기 (한글 유니코드 깨짐 방지)\n",
    "!pip install koreanize-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치하기 이미지 수집을 위한\n",
    "!git clone https://github.com/ndb796/bing_image_downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>1. 학습용 데이터셋 만들기 - 이미지 크롤링을 활용한 학습 이미지 수집</b>\n",
    "\n",
    "* 이미지를 일일히 다운받는것은 너무 비효율적이기 때문에 간단한 크롤러를 활욜해서 데이터를 수집합니다. 추후 생성형 AI를 통해 데이터셋을 무수히 재 생산할수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from bing_image_downloader.bing_image_downloader import downloader\n",
    "\n",
    "# 이미지 저장 디렉토리 지정\n",
    "directory_list = [\n",
    "    './custom_dataset/train/',\n",
    "    './custom_dataset/test/',\n",
    "]\n",
    "\n",
    "# 초기 디렉토리 만들기\n",
    "for directory in directory_list:\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# 수집한 이미지를 학습 데이터와 평가 데이터로 구분하는 함수\n",
    "def dataset_split(query, train_cnt):\n",
    "    # 학습 및 평가 데이터셋 디렉토리 만들기\n",
    "    for directory in directory_list:\n",
    "        if not os.path.isdir(directory + '/' + query):\n",
    "            os.makedirs(directory + '/' + query)\n",
    "    # 학습 및 평가 데이터셋 준비하기\n",
    "    cnt = 0\n",
    "    for file_name in os.listdir(query):\n",
    "        if cnt < train_cnt:\n",
    "            print(f'[Train Dataset] {file_name}')\n",
    "            shutil.move(query + '/' + file_name, './custom_dataset/train/' + query + '/' + file_name)\n",
    "        else:\n",
    "            print(f'[Test Dataset] {file_name}')\n",
    "            shutil.move(query + '/' + file_name, './custom_dataset/test/' + query + '/' + file_name)\n",
    "        cnt += 1\n",
    "    shutil.rmtree(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>검색대상 - [송혜교] 아무나 가능</b> 이미지 크롤링을 진행하고 데이터셋을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '송혜교'\n",
    "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
    "dataset_split(query, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>다른 캐릭터</b> 이미지 크롤링을 진행하고 데이터셋을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '송태섭'\n",
    "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
    "dataset_split(query, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>마지막 캐릭터</b> 이미지 크롤링을 진행하고 데이터셋을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '도구리'\n",
    "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
    "dataset_split(query, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 학습을 위한 데이터 셋 정리용 라이브러리 들\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(), # 데이터 증진(augmentation)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
    "])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_dir = './custom_dataset'\n",
    "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)\n",
    "test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'test'), transforms_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=4)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "print('학습 데이터셋 크기:', len(train_datasets))\n",
    "print('테스트 데이터셋 크기:', len(test_datasets))\n",
    "\n",
    "class_names = train_datasets.classes\n",
    "print('클래스:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(input, title):\n",
    "    # torch.Tensor를 numpy 객체로 변환\n",
    "    input = input.numpy().transpose((1, 2, 0))\n",
    "    # 이미지 정규화 해제하기\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    input = std * input + mean\n",
    "    input = np.clip(input, 0, 1)\n",
    "    # 이미지 출력\n",
    "    plt.imshow(input)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 학습 데이터를 배치 단위로 불러오기\n",
    "iterator = iter(train_dataloader)\n",
    "\n",
    "# 현재 배치를 이용해 격자 형태의 이미지를 만들어 시각화\n",
    "inputs, classes = next(iterator)\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
